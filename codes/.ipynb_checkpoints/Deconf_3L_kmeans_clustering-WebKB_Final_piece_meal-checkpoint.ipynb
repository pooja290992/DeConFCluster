{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pooja/anaconda3/envs/pgupta/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data.dataloader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import *\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime as dtym\n",
    "from datetime import datetime\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import reduce\n",
    "import operator\n",
    "from sklearn.cluster import KMeans\n",
    "from data_processing import *\n",
    "from kmeans_pytorch import kmeans\n",
    "from sklearn import preprocessing\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threads: 2\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(2)\n",
    "print('threads:',torch.get_num_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calOutShape(input_shape, ksize1 = 3,ksize2 = 3, ksize3 = 3,stride = 1,\n",
    "                maxpool1 = False, maxpool2 = False, maxpool3 = False, mpl_ksize = 2):\n",
    "#     print('mpl_ksize in calOutShape:',mpl_ksize)\n",
    "    mpl_stride = 2\n",
    "    pad = ksize1//2\n",
    "    dim1 = int((input_shape[2] - ksize1 + 2 * pad)/stride) + 1\n",
    "    if maxpool1 == True:\n",
    "        dim1 = (dim1 - mpl_ksize)//mpl_stride + 1\n",
    "    pad = ksize2//2\n",
    "    dim1 = int((dim1 - ksize2 + 2 * pad)/stride) + 1\n",
    "    if maxpool2 == True:\n",
    "        dim1 = (dim1 - mpl_ksize)//mpl_stride + 1\n",
    "    pad = ksize3//2\n",
    "    dim1 = int((dim1 - ksize3 + 2 * pad)/stride) + 1\n",
    "    if maxpool3 == True:\n",
    "        dim1 = (dim1 - mpl_ksize)//mpl_stride + 1\n",
    "#     print('dim1 :{}'.format(dim1))\n",
    "    return dim1\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "    total_num_atoms = 0\n",
    "    def __init__(self,input_shape, out_planes1 = 8, out_planes2 = 16, out_planes3 = 16, \n",
    "                 ksize1 = 3,ksize2 = 3, ksize3 = 3,\n",
    "                 maxpool1 = False, maxpool2 = False, maxpool3 = False,\n",
    "                 mpl_ksize = 2, num_channels = 2, activFunc = 'selu', atom_ratio = 0.5):\n",
    "        \n",
    "        super(Transform, self).__init__()\n",
    "        self.ksize1 = ksize1\n",
    "        self.ksize2 = ksize2\n",
    "        self.ksize3 = ksize3\n",
    "        self.mpl_ksize = mpl_ksize\n",
    "        self.out_planes1 = out_planes1\n",
    "        self.out_planes2 = out_planes2\n",
    "        self.out_planes3 = out_planes3\n",
    "        self.init_T(input_shape)\n",
    "        self.maxpool1 = maxpool1\n",
    "        self.maxpool2 = maxpool2\n",
    "        self.maxpool3 = maxpool3\n",
    "        self.input_shape = input_shape\n",
    "        self.num_channels = num_channels\n",
    "        self.activFunc = activFunc\n",
    "        self.activation = activation_funcs[self.activFunc]\n",
    "        self.i = 1\n",
    "        self.atom_ratio = atom_ratio #0.5\n",
    "        self.init_X()\n",
    "        \n",
    "    \n",
    "    def init_T(self,input_shape):\n",
    "        \n",
    "        conv = nn.Conv1d(input_shape[1], out_channels = self.out_planes1, kernel_size = self.ksize1, \n",
    "                         stride = 1, bias = True)\n",
    "        self.T1 = conv._parameters['weight']\n",
    "        conv = nn.Conv1d(in_channels = self.out_planes1, out_channels = self.out_planes2, kernel_size = self.ksize2, \n",
    "                         stride = 1, bias = True)\n",
    "        self.T2 = conv._parameters['weight']\n",
    "        conv = nn.Conv1d(in_channels = self.out_planes2, out_channels = self.out_planes3, kernel_size = self.ksize3, \n",
    "                         stride = 1, bias = True)\n",
    "        self.T3 = conv._parameters['weight']\n",
    "        \n",
    "        \n",
    "    def init_X(self):\n",
    "        \n",
    "        dim1 = calOutShape(self.input_shape,self.ksize1,self.ksize2,self.ksize3, stride = 1,\n",
    "                           maxpool1 = self.maxpool1, \n",
    "                           maxpool2 = self.maxpool2, maxpool3 = self.maxpool3,\n",
    "                           mpl_ksize = self.mpl_ksize)\n",
    "        \n",
    "        X_shape = [self.input_shape[0],self.out_planes3,dim1]\n",
    "#         print('X shape : ', X_shape)\n",
    "        self.X  = nn.Parameter(torch.randn(X_shape), requires_grad=True)\n",
    "        \n",
    "        self.num_features = self.out_planes3 * dim1 \n",
    "        self.num_atoms = int(self.num_features*self.atom_ratio)#* self.num_channels) #dim2//2\n",
    "#         print('self.num_features : ',self.num_features)\n",
    "#         print('self.num_atoms : ',self.num_atoms)\n",
    "        Transform.total_num_atoms += self.num_atoms\n",
    "#         print('Transform.total_num_atoms : ',Transform.total_num_atoms)\n",
    "        \n",
    "    def init_T_tilde(self):\n",
    "        T_shape = [Transform.total_num_atoms,self.num_features]\n",
    "#         print('T_shape : ', T_shape)\n",
    "\n",
    "        self.T = nn.Parameter(torch.randn(T_shape), requires_grad=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(self.T1)\n",
    "        x = F.conv1d(x, weight = self.T1, stride = 1,padding = self.ksize1//2)\n",
    "#         print('x after conv1 : ', x)\n",
    "        if self.maxpool1:\n",
    "            x = F.max_pool1d(x, self.mpl_ksize)\n",
    "#         print('x after mxpl1 : ', x)\n",
    "        x = self.activation(x)\n",
    "#         print('x after activation : ', x)\n",
    "        x = F.conv1d(x, weight = self.T2, stride = 1,padding = self.ksize2//2)\n",
    "#         print('x after conv2 : ', x)\n",
    "        if self.maxpool2:\n",
    "            x = F.max_pool1d(x, self.mpl_ksize)\n",
    "#         print('x after mxpl2 : ', x)    \n",
    "        x = self.activation(x)\n",
    "#         #added check where should we apply activations\n",
    "#         x = self.activation(x)\n",
    "        x = F.conv1d(x, weight = self.T3, stride = 1,padding = self.ksize3//2)\n",
    "#         print('x after conv3 : ', x)\n",
    "        \n",
    "        if self.maxpool3:\n",
    "            x = F.max_pool1d(x, self.mpl_ksize)\n",
    "        y = torch.mm(self.T,x.view(x.shape[0],-1).t())\n",
    "#         print('x after multply : ', x)\n",
    "#         print('*'*100)\n",
    "        return x, y\n",
    "        \n",
    "          \n",
    "    def get_params(self):\n",
    "        return self.T1, self.T2, self.T3, self.X, self.T\n",
    "    \n",
    "    \n",
    "    def X_step(self):\n",
    "        self.X.data = torch.clamp(self.X.data, min=0)\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    def get_TZ_Dims(self):\n",
    "        return self.num_features, Transform.total_num_atoms, self.input_shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepareChannels(data_source,X, out_planes1 = 8, out_planes2 = 16, out_planes3 = 16,\n",
    "                 ksize1 = 3, ksize2 = 3, ksize3 = 3, maxpool1 = True, maxpool2 = True, \n",
    "                 maxpool3 = True, mpl_ksize = 2, num_classes = 6, \n",
    "                 num_channels = 3, activFunc = 'selu',atom_ratio = 0.5):\n",
    "    channels_trnsfrm = nn.ModuleList()\n",
    "    if data_source == \"3sources\":\n",
    "        print('3sources')\n",
    "    elif data_source == \"BBC\":\n",
    "        print('BBC') \n",
    "    elif data_source == \"Mfeat\":\n",
    "        print('Mfeat')\n",
    "    elif data_source == \"100leaves\":\n",
    "        print('100leaves')\n",
    "    elif data_source == \"WebKB\":\n",
    "        print('WebKB')\n",
    "    for nc in range(num_channels): \n",
    "#         print('nc : ',nc)\n",
    "        #input_shape \n",
    "        t = Transform(input_shape = (X[nc].shape[0],1,X[nc].shape[1]), out_planes1 = out_planes1, \n",
    "                      out_planes2 = out_planes2, out_planes3 = out_planes3, ksize1 = ksize1,\n",
    "                      ksize2 = ksize2, ksize3 = ksize3, maxpool1 = maxpool1, \n",
    "                      maxpool2 = maxpool2, maxpool3 = maxpool3, \n",
    "                      mpl_ksize = mpl_ksize, num_channels = num_channels,\n",
    "                      activFunc = activFunc, atom_ratio = atom_ratio)\n",
    "\n",
    "        channels_trnsfrm.append(t)\n",
    "    \n",
    "    #initializing the T tilde\n",
    "    for nc in range(num_channels): \n",
    "        channels_trnsfrm[nc].init_T_tilde()\n",
    "        \n",
    "    return channels_trnsfrm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module): \n",
    "    def __init__(self, source, channels_trnsfrm,out_planes1 = 8, out_planes2 = 16, out_planes3 = 16, \n",
    "                 ksize1 = 3, ksize2 = 3, ksize3 = 3, maxpool1 = False, maxpool2 = False,\n",
    "                 maxpool3 = False, mpl_ksize = 2, num_classes = 6, nclusters = 6, \n",
    "                 num_channels = 2, activFunc = 'selu',atom_ratio = 0.5, loss_func = 'kmeans'):\n",
    "        \n",
    "        super(Network, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.channels_trnsfrm = channels_trnsfrm   \n",
    "        self.num_classes = num_classes\n",
    "        self.nclusters = nclusters\n",
    "        self.num_features, self.num_atoms, self.input_shape = self.channels_trnsfrm[0].get_TZ_Dims()\n",
    "        Z_shape = [self.num_atoms, self.input_shape]\n",
    "#         print('Z_shape : ', Z_shape)\n",
    "        self.Z = nn.Parameter(torch.randn(Z_shape), requires_grad = True)\n",
    "        self.pred_list = []\n",
    "        self.tl_features = []\n",
    "        self.init_TX()\n",
    "        \n",
    "        \n",
    "    def init_TX(self):\n",
    "        self.T1  = []\n",
    "        self.T2 = []\n",
    "        self.T3 = []\n",
    "        self.T = []\n",
    "        self.X_list = []\n",
    "        for nc in range(self.num_channels): \n",
    "            T1, T2, T3, X, T = self.channels_trnsfrm[nc].get_params()\n",
    "#             print('X shape : init_TX', X.shape)\n",
    "            self.T1.append(T1)\n",
    "            self.T2.append(T2)\n",
    "            self.T3.append(T3)\n",
    "            self.X_list.append(X)\n",
    "            self.T.append(T)\n",
    "        self.T1 = torch.stack(self.T1,1)\n",
    "        self.T2 = torch.stack(self.T2,1)\n",
    "        self.T3 = torch.stack(self.T3,1)\n",
    "        #self.X_list = torch.stack(self.X_list,1) \n",
    "        self.T = torch.cat(self.T,1) \n",
    "#         print('self.T1.shape : ', self.T1.shape)\n",
    "#         print('self.T2.shape : ', self.T2.shape)\n",
    "#         print('self.T3.shape : ', self.T3.shape)\n",
    "#         print('self.T.shape : ', self.T.shape)\n",
    "        \n",
    "        \n",
    "    def forward(self,input_x,clabels):\n",
    "        \n",
    "        self.pred_list = []\n",
    "        self.outp = []\n",
    "#         print('input_x.shape : ', input_x.shape)\n",
    "        #to be changed \n",
    "        for nc in range(self.num_channels):\n",
    "            x = input_x[nc]\n",
    "            x = x.reshape(x.shape[0],1,x.shape[1])\n",
    "#             print('x.shape : ', x.shape)\n",
    "            temp_out, temp_outp = self.channels_trnsfrm[nc](x)\n",
    "#             print('temp_out.shape : {}, temp_outp.shape : {}', temp_out.shape, temp_outp.shape)\n",
    "            temp_out = temp_out.view(temp_out.size(0),-1)\n",
    "            self.pred_list.append(temp_out)\n",
    "            self.outp.append(temp_outp)\n",
    "            \n",
    "#         print('self.pred_list length : ', len(self.pred_list))\n",
    "#         print('self.outp length : ', len(self.outp))\n",
    "        \n",
    "        i = 0\n",
    "        for nc in range(self.num_channels):\n",
    "            if i == 0:\n",
    "                self.tl_features = self.outp[nc] \n",
    "            i += 1\n",
    "            self.tl_features += self.outp[nc]\n",
    "            \n",
    "        #print('features after FC - Linear TL:',self.tl_features)\n",
    "        #print('*'*50)\n",
    "        print('features shape after FC - Linear TL:',self.tl_features.shape)\n",
    "\n",
    "        return self.tl_features\n",
    "\n",
    "    \n",
    "    \n",
    "    def X_step(self):\n",
    "        \n",
    "        for nc in range(self.num_channels): \n",
    "            self.channels_trnsfrm[nc].X_step()\n",
    "        \n",
    "        \n",
    "    def Z_step(self):\n",
    "    \n",
    "        self.Z.data = torch.clamp(self.Z.data, min = 0)\n",
    "\n",
    "    \n",
    "    def conv_loss_distance(self, batch_idx, batch_size):\n",
    "        \n",
    "        self.init_TX()\n",
    "        \n",
    "        loss = 0.0\n",
    "#         print('self.X_list len : ', len(self.X_list), self.X_list[0].shape)\n",
    "#         print('self.pred_list : ', self.pred_list)\n",
    "        for i in range(len(self.pred_list)): \n",
    "            predictions = self.pred_list[i].view(self.pred_list[i].size(0), -1)\n",
    "            \n",
    "            X = self.X_list[i].view(self.X_list[i].size(0),-1)\n",
    "            #X = X[batch_idx * batch_size : batch_idx * batch_size + batch_size]\n",
    "            #print('X shape : ', X.shape)\n",
    "            \n",
    "            Y = predictions - X[0:predictions.shape[0]]\n",
    "            loss += Y.pow(2).mean()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def conv_loss_logdet(self):\n",
    "\n",
    "        loss = 0.0\n",
    "        \n",
    "        for T in self.T1:\n",
    "            T = T.view(T.shape[0],-1)\n",
    "            U, s, V = torch.svd(T)\n",
    "            loss += -s.log().sum()\n",
    "            \n",
    "        for T in self.T2:\n",
    "            T = T.view(T.shape[0],-1)\n",
    "            U, s, V = torch.svd(T)\n",
    "            loss += -s.log().sum()\n",
    "            \n",
    "        for T in self.T3:\n",
    "            T = T.view(T.shape[0],-1)\n",
    "            U, s, V = torch.svd(T)\n",
    "            loss += -s.log().sum()\n",
    "            \n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def conv_loss_frobenius(self):\n",
    "        \n",
    "        loss = 0.0\n",
    "        \n",
    "        for T in self.T1:\n",
    "            loss += T.pow(2).sum()\n",
    "        \n",
    "        for T in self.T2:\n",
    "            loss += T.pow(2).sum()\n",
    "        \n",
    "        for T in self.T3:\n",
    "            loss += T.pow(2).sum()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def loss_distance(self, batch_idx, batch_size):\n",
    "\n",
    "        loss = 0.0\n",
    "        \n",
    "        predictions = self.tl_features\n",
    "#         print('predictions.shape : ', predictions.shape)\n",
    "#         print('self.Z.shape : ', self.Z.shape)\n",
    "#        Z = self.Z[:,batch_idx * batch_size : batch_idx * batch_size + batch_size]\n",
    "#         print('Z.shape : ', self.Z.shape)\n",
    "        Y = predictions - self.Z[:,0:predictions.shape[1]] #Z\n",
    "        loss += Y.pow(2).mean()    \n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def loss_logdet(self):\n",
    "        \n",
    "        loss = 0.0\n",
    "        \n",
    "#         T = torch.stack(self.T,1)\n",
    "#         T = self.T\n",
    "#         print('T shape in loss_logdet func : ', T.shape)\n",
    "        \n",
    "        T = self.T.view(self.T.shape[0],-1)\n",
    "        U, s, V = torch.svd(T)\n",
    "        loss = -s.log().sum()\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "        \n",
    "    def loss_frobenius(self):\n",
    "        \n",
    "        loss = 0.0       \n",
    "        loss = self.T.pow(2).sum()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def computeLoss(self, lam, mu, km_reg, batch_idx, batch_size):\n",
    "        t0 = time.time()\n",
    "        loss1 = self.conv_loss_distance(batch_idx, batch_size)\n",
    "        loss2 = self.conv_loss_frobenius() * mu\n",
    "        loss3 = self.conv_loss_logdet() * lam\n",
    "        loss4 = self.loss_distance(batch_idx, batch_size)\n",
    "        loss5 = self.loss_frobenius() * mu\n",
    "        loss6 = self.loss_logdet() * lam\n",
    "        loss_ctl = loss1 + loss2 + loss3 + loss4 + loss5 + loss6 \n",
    "        t1 = time.time()\n",
    "#         print('Time taken for ctl loss : ', str(dtym.timedelta(seconds = t1 - t0)))\n",
    "#         print(\"computed ctl\")\n",
    "        loss = loss_ctl\n",
    "        \n",
    "        return loss, loss_ctl\n",
    "\n",
    "    \n",
    "    def getTZ(self):\n",
    "        \n",
    "        return self.T.view(self.T.shape[0],-1), self.Z\n",
    "    \n",
    "    \n",
    "    def getX(self):\n",
    "        \n",
    "        return self.X_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(X, Y, source, lamda, mean, km_reg, out_pl1, out_pl2, out_pl3, \n",
    "           ks1, ks2, ks3, maxpl1, maxpl2, maxpl3,\n",
    "           mpl_ks, batch_size, xstep_flg, zstep_flg, epochs = 50, lr = 0.001, gamma = 0.1, wd = 1e-4, \n",
    "           amsFlg = False, activFunc = 'selu', loss_func = 'kmeans', \n",
    "           atom_ratio = 0.5):\n",
    "#     print('epochs : ', epochs)\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    train_loader = DataLoader(MVCData3Sources(X, Y, source), batch_size = batch_size, num_workers = 0, shuffle = True)\n",
    "#     print('len(train_loader) : ',len(train_loader))\n",
    "    if source == \"WebKB\":\n",
    "        num_channels = X.shape[0]\n",
    "        num_classes = np.unique(Y).shape[0]\n",
    "        n_clusters = num_classes\n",
    "        print('num_channels : {}, num_classes : {}'.format(num_channels, num_classes))\n",
    "    # creating channels networks \n",
    "    channels_trnsfrm = prepareChannels(data_source = source, X = X,\n",
    "                                      out_planes1 = out_pl1, out_planes2 = out_pl2, out_planes3 = out_pl3, \n",
    "                                      ksize1 = ks1, ksize2 = ks2, ksize3 = ks3, \n",
    "                                      maxpool1 = maxpl1, maxpool2 = maxpl2, maxpool3 = maxpl3,\n",
    "                                      mpl_ksize = mpl_ks, num_classes = num_classes, \n",
    "                                      num_channels = num_channels, activFunc = activFunc, \n",
    "                                      atom_ratio = atom_ratio)\n",
    "#     print('channels_trnsfrm :')\n",
    "#     print(channels_trnsfrm)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = Network(source, channels_trnsfrm,out_planes1 = out_pl1, out_planes2 = out_pl2, \n",
    "                 out_planes3 = out_pl3, ksize1 = ks1, ksize2 = ks2, ksize3 = ks3,\n",
    "                 maxpool1 = maxpl1, maxpool2 = maxpl2, maxpool3 = maxpl3,\n",
    "                 mpl_ksize = mpl_ks, num_classes = num_classes, nclusters = n_clusters, num_channels = num_channels, \n",
    "                 activFunc = activFunc,atom_ratio = atom_ratio, loss_func = loss_func)\n",
    "    model.to(device)\n",
    "#     for name, param in model.named_parameters():\n",
    "#         print(name, param)\n",
    "    \n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr = lr, \n",
    "#                                  betas = (0.9, 0.999), eps = 1e-08, weight_decay = wd, amsgrad = amsFlg)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = lr, weight_decay = wd)#,momentum = 0.9)\n",
    "    print_every = 10\n",
    "    steps = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    ctl_losses = []\n",
    "    scores = []\n",
    "    train_accs = []\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "#         print('***EPOCH*** : ',epoch)\n",
    "        model.train()\n",
    "        t00 = time.time()\n",
    "        running_loss = 0.0\n",
    "        ctl_run_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        ypred = []\n",
    "        ytrue = []\n",
    "        data = []\n",
    "#         temp = []\n",
    "        for batch_idx, (vw1,vw2,vw3, labels) in enumerate(train_loader):\n",
    "#             print('batch_idx : ', batch_idx)\n",
    "#             for vw in views: \n",
    "            vw1, vw2, vw3, labels = map(lambda x: Variable(x), [vw1, vw2, vw3, labels])  \n",
    "#                 temp.append(vw)\n",
    "#             data.append(temp)\n",
    "#             temp = []\n",
    "            data = [vw1.to(device),vw2.to(device),vw3.to(device)]\n",
    "            labels = labels.to(device)\n",
    "#             print('data : ',data)\n",
    "#             print('labels : ',labels)\n",
    "#             print('='*20)\n",
    "            labels = labels.float()\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward + backward + optimize\n",
    "            model(data,labels)\n",
    "#             print(\"computing loss!!\")\n",
    "            loss, loss_ctl = model.computeLoss(lamda, mean, km_reg, batch_idx, batch_size)\n",
    "#             print(\"loss computed!!\")\n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient step\n",
    "            optimizer.step()\n",
    "\n",
    "            # proximal step\n",
    "            if xstep_flg:\n",
    "                model.X_step()\n",
    "            if zstep_flg:\n",
    "                model.Z_step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            ctl_run_loss += loss_ctl.item()\n",
    "#             if batch_idx == 0:\n",
    "#                 break\n",
    "        train_losses.append(running_loss/(batch_idx+1))\n",
    "        ctl_losses.append(ctl_run_loss/(batch_idx+1))\n",
    "        t01 = time.time()\n",
    "        print(\"Time taken for one epoch : \", str(dtym.timedelta(seconds = t01 - t00)))\n",
    "        print('*'*100)\n",
    "        print('Train Epoch: {} \\tLoss: {:.4f}'.format(\n",
    "                    epoch, running_loss/(batch_idx + 1)))\n",
    "                \n",
    "    model.eval()\n",
    "    torch.save({\n",
    "            'epochs': epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(), \n",
    "            'model': model\n",
    "            },model_path)             \n",
    "#     print(\"reached here !!\")\n",
    "    S_train = [Variable(torch.from_numpy(X[0]).float(), requires_grad=False), \n",
    "               Variable(torch.from_numpy(X[1]).float(), requires_grad=False), \n",
    "               Variable(torch.from_numpy(X[2]).float(), requires_grad=False)]\n",
    "\n",
    "    Z_train = model(S_train, Y)\n",
    "    Z_train = Z_train.cpu().data.numpy()\n",
    "    Z_train = Z_train.reshape(Z_train.shape[0], -1).T\n",
    "    print(\"Shape of Z_train: \" + str(Z_train.shape))\n",
    "    feat_path = base_path + 'features/' + source + '_' + param_path + '.npy'\n",
    "#     print('feat_path : ', feat_path)\n",
    "    np.save(feat_path,Z_train)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    ypred = KMeans(n_clusters = n_clusters, init=\"k-means++\").fit_predict(Z_train)\n",
    "    pred_df = pd.DataFrame(ypred, columns = ['Predicted'])\n",
    "    pred_df['True'] = Y\n",
    "#     print(ypred)\n",
    "#     print(pred_df)\n",
    "    pred_file_name = res_base_path + 'pred_dcfl3_' + loss_func + param_path + '.csv' \n",
    "    pred_df.to_csv(pred_file_name, index = None)\n",
    "    acc = cluster_acc(Y, ypred)\n",
    "    nmi_val, ari_val = compute_nmi_ari(Y,ypred)\n",
    "    print('k means acc = %.4f, nmi = %.4f, ari = %.4f' % (acc,nmi_val,ari_val))\n",
    "    \n",
    "    scores_dict = {}\n",
    "    scores_dict['source'] = source  \n",
    "    scores_dict['seed'] = seed\n",
    "    scores_dict['wd'] = wd\n",
    "    scores_dict['lr'] = lr\n",
    "    scores_dict['epochs'] = epochs\n",
    "    scores_dict['lamda'] = lamda\n",
    "    scores_dict['mean'] = mean\n",
    "    scores_dict['km_reg'] = km_reg\n",
    "    scores_dict['atm_ratio'] = atom_ratio\n",
    "    scores_dict['ks1'] = ks1\n",
    "    scores_dict['ks2'] = ks2\n",
    "    scores_dict['ks3'] = ks3\n",
    "    scores_dict['out_pl1'] = out_pl1\n",
    "    scores_dict['out_pl2'] = out_pl2\n",
    "    scores_dict['out_pl3'] = out_pl3\n",
    "    scores_dict['maxpl1'] = maxpl1\n",
    "    scores_dict['maxpl2'] = maxpl2\n",
    "    scores_dict['maxpl3'] = maxpl3\n",
    "    scores_dict['amsFlg'] = amsFlg\n",
    "    scores_dict['zstep_flg'] = zstep_flg\n",
    "    scores_dict['xstep_flg'] = xstep_flg\n",
    "    scores_dict['activFunc'] = activFunc\n",
    "    scores_dict['loss_func'] = loss_func\n",
    "    scores_dict['batch_size'] = batch_size\n",
    "    scores_dict['train_loss'] = train_losses\n",
    "    scores_dict['ctl_loss'] = ctl_losses\n",
    "    scores_dict['ari'] = ari_val\n",
    "    scores_dict['nmi'] = nmi_val\n",
    "    scores_dict['cluster_accuracy'] = acc\n",
    "    scores_dict['datetime'] = datetime.now()\n",
    "    t1 = time.time()\n",
    "    print('Time taken for entire training : ', str(dtym.timedelta(seconds = t1 - t0)))\n",
    "    print('*'*50)\n",
    "    return scores_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_configs():\n",
    "    # define scope of configs\n",
    "    n_epochs = [25]\n",
    "    n_batch = [203]\n",
    "    lam_mu_km_list = [(0.01,0.00001,0)]\n",
    "    learning_rate_list = [1e-4]\n",
    "    gamma = [1]\n",
    "    ks_filters = [(4,3,8,3,16,3)]\n",
    "    wd_list = [0.001]\n",
    "    mpl_ks_list = [2]\n",
    "    maxpool_list = [(False, False, False)]\n",
    "    activations = ['selu']\n",
    "    atom_ratio = [0.15]\n",
    "    amsFlg = ['SGD']\n",
    "    xstep_flg = [True]\n",
    "    zstep_flg = [True]\n",
    "    # create configs\n",
    "    configs = list()\n",
    "    for i in n_epochs:\n",
    "        for j in n_batch:\n",
    "            for m in lam_mu_km_list:\n",
    "                for l in learning_rate_list:\n",
    "                    for g in gamma:\n",
    "                        for ks_f in ks_filters:\n",
    "                            for wd in wd_list:\n",
    "                                for mpl_ks in mpl_ks_list:\n",
    "                                    for maxpools in maxpool_list: \n",
    "                                        for activ_func in activations:\n",
    "                                            for atm in atom_ratio:\n",
    "                                                for ams in amsFlg:\n",
    "                                                    for x in xstep_flg:\n",
    "                                                        for z in zstep_flg:\n",
    "                                                            cfg = [i, j, m, l, g, ks_f, wd, mpl_ks, maxpools, \n",
    "                                                                   activ_func, atm,ams,x,z]\n",
    "                                                            configs.append(cfg)\n",
    "    print('Total configs: %d' % len(configs))\n",
    "    return configs\n",
    "\n",
    "\n",
    "def createParamPath(epochs, batch_size, lamda, mean, km_reg, lr, gamma, ks_f, wd, mpl_ks, maxpools, amsFlg, activFunc, \n",
    "                    loss_func, atom_ratio, xstep_flg, zstep_flg):\n",
    "    out_pl1, ks1, out_pl2, ks2, out_pl3, ks3 = ks_f\n",
    "    maxpl1, maxpl2, maxpl3 = maxpools\n",
    "    if custom_batch_size_flag == True:\n",
    "        param_path = 'final_ep_' + str(epochs) + '_bs' + str(batch_size) + '_lam' + str(lamda) + '_mu' + str(mean) + '_kmreg' + str(km_reg) +                '_lr' + str(lr) + '_gm' + str(gamma) + '_wd' + str(wd) +  '_ks1_' + str(ks1) + '_ks2' + str(ks2) + '_ks3' + str(ks3) +'_opl1' +                 str(out_pl1) + '_opl2' + str(out_pl2) + '_opl3' + str(out_pl3) +'_mpl1' + str(maxpl1)[0] + '_mpl2' + str(maxpl2)[0] + '_mpl3' + str(maxpl3)[0] +             '_ams' + str(amsFlg) + '_atmrat' + str(atom_ratio) + '_af' + activFunc + '_loss' + loss_func + '_x' + str(xstep_flg)[0] + '_z' + str(zstep_flg)[0] + '_pm'\n",
    "    else:\n",
    "        param_path = 'final_ep_' + str(epochs) + '_lam' + str(lamda) + '_mu' + str(mean) + '_kmreg' + str(km_reg) +                '_lr' + str(lr) + '_gm' + str(gamma) + '_wd' + str(wd) +  '_ks1_' + str(ks1) + '_ks2' + str(ks2) + '_ks3' + str(ks3) +'_opl1' +                 str(out_pl1) + '_opl2' + str(out_pl2) + '_opl3' + str(out_pl3) +'_mpl1' + str(maxpl1)[0] + '_mpl2' + str(maxpl2)[0] + '_mpl3' + str(maxpl3)[0] +             '_ams' + str(amsFlg) + '_atmrat' + str(atom_ratio) + '_af' + activFunc + '_loss' + loss_func + '_x' + str(xstep_flg)[0] + '_z' + str(zstep_flg)[0] \n",
    "    return param_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_funcs = {\n",
    "    'relu' : nn.ReLU(inplace = True),\n",
    "    'selu' : nn.SELU(inplace = True),\n",
    "    'leaky_relu' : nn.LeakyReLU(inplace = True),\n",
    "    'tanh' : nn.Tanh(),\n",
    "    'softsign' : nn.Softsign(),\n",
    "    'softmax' : nn.Softmax(dim = 1),\n",
    "    'sigmoid' : nn.Sigmoid()\n",
    "}\n",
    "\n",
    "loss_funcs = {\n",
    "    'cross_entropy' : nn.CrossEntropyLoss(),\n",
    "    'hinge' : nn.HingeEmbeddingLoss()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configs: 1\n",
      "final_ep_25_bs203_lam0.01_mu1e-05_kmreg0_lr0.0001_gm1_wd0.001_ks1_3_ks23_ks33_opl14_opl28_opl316_mpl1F_mpl2F_mpl3F_amsSGD_atmrat0.15_afselu_losskmeans_xT_zT_pm\n",
      "data loaded !!\n",
      "X.shape :  (3,)\n",
      "Y.shape :  (203,)\n",
      "num_channels : 3, num_classes : 4\n",
      "WebKB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pooja/anaconda3/envs/pgupta/lib/python3.10/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:55.361949\n",
      "****************************************************************************************************\n",
      "Train Epoch: 1 \tLoss: 1780.5867\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:37.739889\n",
      "****************************************************************************************************\n",
      "Train Epoch: 2 \tLoss: 1691.0833\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:54.653500\n",
      "****************************************************************************************************\n",
      "Train Epoch: 3 \tLoss: 1645.5721\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:56.937088\n",
      "****************************************************************************************************\n",
      "Train Epoch: 4 \tLoss: 1619.4814\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:34.338612\n",
      "****************************************************************************************************\n",
      "Train Epoch: 5 \tLoss: 1602.7760\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:59.503469\n",
      "****************************************************************************************************\n",
      "Train Epoch: 6 \tLoss: 1591.2135\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:55.297869\n",
      "****************************************************************************************************\n",
      "Train Epoch: 7 \tLoss: 1582.7123\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:37.075093\n",
      "****************************************************************************************************\n",
      "Train Epoch: 8 \tLoss: 1576.2167\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:54.783195\n",
      "****************************************************************************************************\n",
      "Train Epoch: 9 \tLoss: 1571.0931\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:54.648785\n",
      "****************************************************************************************************\n",
      "Train Epoch: 10 \tLoss: 1566.9215\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:38.711371\n",
      "****************************************************************************************************\n",
      "Train Epoch: 11 \tLoss: 1563.5033\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:57.232982\n",
      "****************************************************************************************************\n",
      "Train Epoch: 12 \tLoss: 1560.6378\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:53.137159\n",
      "****************************************************************************************************\n",
      "Train Epoch: 13 \tLoss: 1558.2217\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:39.672909\n",
      "****************************************************************************************************\n",
      "Train Epoch: 14 \tLoss: 1556.1530\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:03:03.583791\n",
      "****************************************************************************************************\n",
      "Train Epoch: 15 \tLoss: 1554.3394\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:50.983006\n",
      "****************************************************************************************************\n",
      "Train Epoch: 16 \tLoss: 1552.7804\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:38.983937\n",
      "****************************************************************************************************\n",
      "Train Epoch: 17 \tLoss: 1551.4014\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:03:04.738603\n",
      "****************************************************************************************************\n",
      "Train Epoch: 18 \tLoss: 1550.1713\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:46.850716\n",
      "****************************************************************************************************\n",
      "Train Epoch: 19 \tLoss: 1549.0820\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:40.341481\n",
      "****************************************************************************************************\n",
      "Train Epoch: 20 \tLoss: 1548.1031\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:03:09.378516\n",
      "****************************************************************************************************\n",
      "Train Epoch: 21 \tLoss: 1547.2373\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:48.092719\n",
      "****************************************************************************************************\n",
      "Train Epoch: 22 \tLoss: 1546.4619\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:41.632458\n",
      "****************************************************************************************************\n",
      "Train Epoch: 23 \tLoss: 1545.7418\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:03:05.475507\n",
      "****************************************************************************************************\n",
      "Train Epoch: 24 \tLoss: 1545.1045\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Time taken for one epoch :  0:02:50.715793\n",
      "****************************************************************************************************\n",
      "Train Epoch: 25 \tLoss: 1544.5137\n",
      "features shape after FC - Linear TL: torch.Size([5191, 203])\n",
      "Shape of Z_train: (203, 5191)\n",
      "k means acc = 0.7783, nmi = 0.4447, ari = 0.5257\n",
      "Time taken for entire training :  1:11:13.809642\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/\"\n",
    "base_path = '../' \n",
    "loss_func = 'kmeans'\n",
    "source = 'WebKB'\n",
    "model_base_path = base_path + 'models/Dcf_l3' #+ str_fl_nm + '/' \n",
    "res_base_path = base_path + 'Results/ablation/piecemeal/'  + source + '/' + source + '_'\n",
    "\n",
    "# base_string = 'dcf_l2_smi_sign' + str_fl_nm + '_' + loss_func + '_' \n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "configs_list = model_configs()\n",
    "custom_batch_size_flag = True\n",
    "config_result_dict = {}\n",
    "save_flag = 0\n",
    "seed = 42\n",
    "# g_cpu = torch.Generator()\n",
    "# g_cpu.manual_seed(seed)\n",
    "mode = 'train'\n",
    "for idx, config in enumerate(configs_list):#[8:]):\n",
    "    t0 = time.time()\n",
    "    log_interval = 1 \n",
    "    cnt = 0 \n",
    "    epochs, batch_size, lamda_mean_kmreg, lr, gamma, ks_f, wd, mpl_ks, maxpools, activFunc, atom_ratio, amsFlg, xstep_flg, zstep_flg = config\n",
    "    out_pl1, ks1, out_pl2, ks2, out_pl3, ks3 = ks_f\n",
    "    maxpl1, maxpl2, maxpl3 = maxpools\n",
    "    lamda, mean, km_reg = lamda_mean_kmreg\n",
    "    if custom_batch_size_flag == False:\n",
    "        batch_size = X[0].shape[0]\n",
    "    param_path = createParamPath(epochs, batch_size, lamda, mean, km_reg, lr, gamma, ks_f, wd, mpl_ks, maxpools, amsFlg, \n",
    "                                 activFunc, loss_func, atom_ratio, xstep_flg, zstep_flg)\n",
    "    model_path = model_base_path + source + '_model' +  param_path + '_reg' + str(idx) + '.pth'\n",
    "    print(param_path)\n",
    "    file_path = data_path + source + '.mat'\n",
    "    X, Y = getData(file_path)\n",
    "#     print(X)\n",
    "    for vw_idx in range(X.shape[0]):\n",
    "        X[vw_idx] = normalizeData(X[vw_idx].T)\n",
    "    print('data loaded !!')\n",
    "    print('X.shape : ', X.shape)\n",
    "    print('Y.shape : ', Y.shape)\n",
    "    scores_dict = train_on_batch(X, Y, source, lamda, mean, km_reg, out_pl1, out_pl2, out_pl3, \n",
    "           ks1, ks2, ks3, maxpl1, maxpl2, maxpl3, \n",
    "           mpl_ks, batch_size, xstep_flg, zstep_flg, epochs = epochs, lr = lr, \n",
    "           gamma = gamma, wd = wd, \n",
    "           amsFlg = amsFlg, activFunc = activFunc, loss_func = loss_func, \n",
    "           atom_ratio = atom_ratio)\n",
    "    scores_df = pd.DataFrame.from_dict(scores_dict, orient = 'index').T.reset_index().drop(columns = ['index'])\n",
    "#     print('scores_df : ')\n",
    "#     print(scores_df.head())\n",
    "    os.remove(model_path)\n",
    "    results_file_name = res_base_path + 'res_dcfl3_' + loss_func + param_path + '.csv'\n",
    "    results_file_name2 = res_base_path + 'res_dcfl3_' + loss_func + '_pm.csv'\n",
    "    \n",
    "    if not os.path.exists(results_file_name):\n",
    "        scores_df.to_csv(results_file_name, sep = ',', index = None)\n",
    "    else:\n",
    "        scores_df.to_csv(results_file_name, mode = 'a', sep = ',', index = None, header = None)\n",
    "        \n",
    "    if not os.path.exists(results_file_name2):\n",
    "        scores_df.to_csv(results_file_name2, sep = ',', index = None)\n",
    "    else:\n",
    "        scores_df.to_csv(results_file_name2, mode = 'a', sep = ',', index = None, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
